{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtnT7pxkzMPRjhr6rZOYpy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YiENzu46Fcy3"},"outputs":[],"source":["# reference : https://towardsdatascience.com/how-to-easily-cluster-textual-data-in-python-ab27040b07d8\n","Sum_of_squared_distances = []\n","K = range(2,25)\n","for k in tqdm(K):\n","    km = KMeans(n_clusters=k, max_iter=200, n_init=10,  init='k-means++')\n","    km = km.fit(embeddings)\n","    Sum_of_squared_distances.append(km.inertia_)\n","plt.plot(K, Sum_of_squared_distances, 'bx-')\n","plt.xlabel('k')\n","plt.ylabel('Sum_of_squared_distances')\n","plt.title('Elbow Method For Optimal k')\n","plt.show()"]},{"cell_type":"code","source":["\n","# Instantiate the clustering model and visualizer\n","km = KMeans(n_clusters=k, max_iter=200, n_init=10,  init='k-means++')\n","visualizer = KElbowVisualizer(km, k=(2,25))\n"," \n","visualizer.fit(embeddings)        # Fit the data to the visualizer\n","visualizer.show()        # Finalize and render the figure"],"metadata":{"id":"uwz3DrIIHDuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import KMeans Model\n","# Create Kmeans object and fit it to the training data \n","kmeans = KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=200, random_state=42).fit(embeddings)\n","\n","# Get the labels using KMeans\n","pred_labels = kmeans.labels_"],"metadata":{"id":"PxnIOS6YHJPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reference : https://towardsdatascience.com/elbow-method-is-not-sufficient-to-find-best-k-in-k-means-clustering-fc820da0631d\n","fig, ax = plt.subplots(4, 2, figsize=(30,16))\n","for i in range(2, 10):\n","    '''\n","    Create KMeans instances for different number of clusters\n","    '''\n","    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=200, random_state=42)\n","    q, mod = divmod(i, 2)\n","    '''\n","    Create SilhouetteVisualizer instance with KMeans instance\n","    Fit the visualizer\n","    '''\n","    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n","    visualizer.fit(embeddings) "],"metadata":{"id":"Aq3UCCnhHGBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import metrics\n","# Compute DBI score\n","dbi = metrics.davies_bouldin_score(embeddings, pred_labels)\n","\n","# Compute Silhoutte Score\n","ss = metrics.silhouette_score(embeddings, pred_labels , metric='euclidean')\n","\n","# Print the DBI and Silhoutte Scores\n","print(\"DBI Score: \", dbi, \"\\nSilhoutte Score: \", ss)"],"metadata":{"id":"kYK7VeEUHMZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# refrence used : https://www.sbert.net/docs/pretrained_models.html\n","\n","#!pip install sentence-transformers\n","#from sentence_transformers import SentenceTransformer\n","#sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n","#query = data.iloc[0,1]\n","#sentence_embeddings = sbert_model.encode(query)"],"metadata":{"id":"ceVOniQKHRrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# based on above visualizations we chose : \n","query = \"How many people live in London?\"\n","docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n","\n","#Load the model\n","model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n","\n","#Encode query and documents\n","query_emb = model.encode(query)"],"metadata":{"id":"7lBNmdRxHY_w"},"execution_count":null,"outputs":[]}]}